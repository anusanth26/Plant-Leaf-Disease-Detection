{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5008d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc67b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model and components...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xgboost_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# LOADING SAVED COMPONENTS\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading saved model and components...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgboost_model.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_encoder.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_scaler.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ANUSANTH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[0;32m    733\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, ensure_native_byte_order\u001b[38;5;241m=\u001b[39mensure_native_byte_order)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m             fobj,\n\u001b[0;32m    738\u001b[0m             validated_mmap_mode,\n\u001b[0;32m    739\u001b[0m         ):\n\u001b[0;32m    740\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    741\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    742\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    743\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xgboost_model.joblib'"
     ]
    }
   ],
   "source": [
    "# LOADING SAVED COMPONENTS\n",
    "print(\"Loading saved model and components...\")\n",
    "model = joblib.load('xgboost_model.joblib')\n",
    "label_encoder = joblib.load('label_encoder.joblib')\n",
    "scaler = joblib.load('feature_scaler.joblib')\n",
    "print(\"Loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ac3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING THE SAME FEATURE EXTRACTION METHODS FOR FURTHER CUSTOM IMAGE PREDICTIONS\n",
    "IMAGE_SIZE = (256, 256)\n",
    "LBP_RADIUS = 1\n",
    "LBP_POINTS = 8 * LBP_RADIUS\n",
    "LBP_METHOD = 'uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT COLOR, TEXTURE, AND SHAPE FEATURES\n",
    "\n",
    "def extract_color_features(image):\n",
    "    \n",
    "    features = []\n",
    "    for i in range(3):\n",
    "        features.extend([np.mean(image[:, :, i]), np.std(image[:, :, i])])\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    for i in range(3):\n",
    "        features.extend([np.mean(hsv[:, :, i]), np.std(hsv[:, :, i])])\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    features.extend(hist.flatten())\n",
    "    return features\n",
    "\n",
    "def extract_texture_features(image):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray, LBP_POINTS, LBP_RADIUS, method=LBP_METHOD)\n",
    "    (lbp_hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, LBP_POINTS + 3), range=(0, LBP_POINTS + 2))\n",
    "    lbp_hist = lbp_hist.astype(\"float\") / (lbp_hist.sum() + 1e-7)\n",
    "    glcm = graycomatrix(gray, distances=[1, 3, 5], angles=[0, np.pi/4, np.pi/2], levels=256, symmetric=True, normed=True)\n",
    "    glcm_props = [np.mean(graycoprops(glcm, prop)) for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']]\n",
    "    return np.hstack([lbp_hist, glcm_props]).tolist()\n",
    "\n",
    "def extract_shape_features(image):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours: return [0, 0, 0]\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    aspect_ratio = float(w) / h if h != 0 else 0\n",
    "    area = cv2.contourArea(c)\n",
    "    rect_area = w * h\n",
    "    extent = float(area) / rect_area if rect_area != 0 else 0\n",
    "    hull = cv2.convexHull(c)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area if hull_area != 0 else 0\n",
    "    return [aspect_ratio, extent, solidity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_custom_image(image_path):\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return \"Error: Image not found or cannot be read.\"\n",
    "    image_resized = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "    # EXTRACT ALL FEATURES INCLUDING COLOR, TEXTURE AND SHAPE\n",
    "    color_feats = extract_color_features(image_resized)\n",
    "    texture_feats = extract_texture_features(image_resized)\n",
    "    shape_feats = extract_shape_features(image_resized)\n",
    "    \n",
    "    # COMBINING ALL FEATURES\n",
    "    features = color_feats + texture_feats + shape_feats\n",
    "    \n",
    "    features_reshaped = np.array(features).reshape(1, -1)\n",
    "    features_scaled = scaler.transform(features_reshaped)\n",
    "    \n",
    "    # PREDICT THE OUTPUT FOR THE GIVEN IMAGE\n",
    "    prediction_numeric = model.predict(features_scaled)\n",
    "    prediction_label = label_encoder.inverse_transform(prediction_numeric)[0]\n",
    "    \n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_path = '/content/tomato_mosaic_virus.JPG' \n",
    "    \n",
    "predicted_disease = predict_custom_image(custom_image_path)\n",
    "print(f\"The predicted disease for the image is: {predicted_disease}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
